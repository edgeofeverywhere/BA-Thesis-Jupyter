{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab Setup, Installation of Prerequisites, Modifications\n",
    "If running offline, many of the steps here do not work out of the box unless iPython is setup properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oSuebaEk3A8O"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xghZIFZsqAlq"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "### not sure what ml libraries hopper comes with - or your setup for that matter\n",
    "### you should only need to install / use pytorch for now provided you don't modify the example calls\n",
    "### assuming no sudo access...\n",
    "\n",
    "# apt update && apt install ffmpeg not required for colab\n",
    "\n",
    "pip install brian2hears\n",
    "pip install brian2\n",
    "pip install importlib\n",
    "pip install sklearn\n",
    "pip install scipy\n",
    "pip install librosa\n",
    "pip install tqdm\n",
    "pip install visualkeras\n",
    "\n",
    "wget https://github.com/bBoxType/FiraSans/archive/refs/heads/master.zip -O FiraSans.zip\n",
    "\n",
    "unzip FiraSans.zip\n",
    "sudo mkdir -p /usr/local/share/fonts/truetype/fira\n",
    "\n",
    "find FiraSans-master/Fira_Sans_4_3/Fonts/Fira_Sans_TTF_4301 -type f -name \"*.ttf\" -exec sudo cp {} /usr/local/share/fonts/truetype/fira/ \\;\n",
    "sudo fc-cache -fv\n",
    "\n",
    "\n",
    "### your python version may vary! -- check path to this library once you've finished pip installing.\n",
    "file_path=\"/usr/local/lib/python3.10/dist-packages/brian2hears/filtering/filterbanklibrary.py\"\n",
    "cp \"$file_path\" \"${file_path}.bak\" || { echo \"Backup failed\"; exit 1; }\n",
    "perl -i -0pe '\n",
    "    s/(class ApproximateGammatone\\(LinearFilterbank\\)(?:.*?\\n)*?)(\\s*def __init__\\(self,)/$1    def get_individual_filter_outputs(self, input_signal):\\n        filter_outputs = []  # List to store the outputs of each filter for each bandwidth\\n        for i in range(len(self.cf)):\\n            bandwidth_filter_outputs = []  # List to store the outputs of each filter for the current bandwidth\\n            for j in range(self.order):\\n                # Apply the j-th filter for the i-th bandwidth to the input signal\\n                output = self.filters[i * self.order + j].apply(input_signal)\\n                bandwidth_filter_outputs.append(output)  # Append the output to the list of filter outputs\\n            filter_outputs.append(bandwidth_filter_outputs)  # Append the outputs for the current bandwidth to the main list\\n        return filter_outputs\\n$2/s' \"$file_path\" || echo \"Failed to insert get_individual_filter_outputs\"\n",
    "\n",
    "# appends the 'process' method if not already present\n",
    "perl -i -0pe '\n",
    "    $process_method_code = qq{\n",
    "        def process(self, func=None, duration=None, buffersize=32):\n",
    "            if self.use_individual_outputs:\n",
    "                if duration is None:\n",
    "                    duration = self.duration\n",
    "                if not isinstance(duration, int):\n",
    "                    duration = int(duration * self.samplerate)\n",
    "\n",
    "                self.buffer_init()\n",
    "                total_output = []\n",
    "                for start in range(0, duration, buffersize):\n",
    "                    end = min(start + buffersize, duration)\n",
    "                    input_signal = self.source.buffer_fetch(start, end)\n",
    "                    output = self.get_individual_filter_outputs(input_signal)\n",
    "                    total_output.append(output)\n",
    "                return np.concatenate(total_output, axis=0)\n",
    "            else:\n",
    "                return super().process(func, duration, buffersize)\n",
    "    };\n",
    "    if (/class ApproximateGammatone\\(LinearFilterbank\\)/) {\n",
    "        unless (/def process\\(self, func=None, duration=None, buffersize=32\\):/) {\n",
    "            s/(def get_individual_filter_outputs\\(self, input_signal\\):.*?return filter_outputs\\n)/$1\\n$process_method_code/s;\n",
    "        }\n",
    "    }\n",
    "' \"$file_path\" || echo \"Failed to insert process method\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3EPxgIqCiOEV"
   },
   "outputs": [],
   "source": [
    "# optional\n",
    "# !pip install arrayfire==3.8.0+cu112 -f https://repo.arrayfire.com/python/wheels/3.8.0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yK-5M3rsp9C4"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "def modify_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    new_init_code = \"\"\"\n",
    "    def __init__(self, source, cf, bandwidth, order=4, use_individual_outputs=False):\n",
    "        self.cf = cf\n",
    "        cf = np.asarray(np.atleast_1d(cf))\n",
    "        bandwidth = np.asarray(np.atleast_1d(bandwidth))\n",
    "        self.samplerate = source.samplerate\n",
    "        dt = float(1 / self.samplerate)\n",
    "        phi = 2 * np.pi * bandwidth * dt\n",
    "        theta = 2 * np.pi * cf * dt\n",
    "        cos_theta = np.cos(theta)\n",
    "        sin_theta = np.sin(theta)\n",
    "        alpha = -np.exp(-phi) * cos_theta\n",
    "        b0 = np.ones(len(cf))\n",
    "        b1 = 2 * alpha\n",
    "        b2 = np.exp(-2 * phi)\n",
    "        z1 = (1 + alpha * cos_theta) - (alpha * sin_theta) * 1j\n",
    "        z2 = (1 + b1 * cos_theta) - (b1 * sin_theta) * 1j\n",
    "        z3 = (b2 * np.cos(2 * theta)) - (b2 * np.sin(2 * theta)) * 1j\n",
    "        tf = (z2 + z3) / z1\n",
    "        a0 = abs(tf)\n",
    "        a1 = alpha * a0\n",
    "        self.filt_a = np.dstack((np.array([b0, b1, b2]).T,)*order)\n",
    "        self.filt_b = np.dstack((np.array([a0, a1, np.zeros(len(cf))]).T,)*order)\n",
    "        super().__init__(source, self.filt_b, self.filt_a)\n",
    "    \"\"\".strip()\n",
    "\n",
    "    pattern = re.compile(r'(def __init__\\(self, source, cf,  bandwidth,order=4\\):)(.*?)(?=\\n\\w)', re.DOTALL)\n",
    "    content = re.sub(pattern, new_init_code, content)\n",
    "    with open(file_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "modify_file('/usr/local/lib/python3.10/dist-packages/brian2hears/filtering/filterbanklibrary.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNT_loi6ZZHg"
   },
   "outputs": [],
   "source": [
    "%%shell\n",
    "#!/bin/bash\n",
    "\n",
    "# Base directory\n",
    "BASE_DIR=\"Model\"\n",
    "\n",
    "SUBDIRS=(\"graphics\" \"graphics_sample2\" \"graphics_sample3\" \"graphics_sample4\" \"graphics_sample5\")\n",
    "SUBFOLDERS=(\"maximal_entropy\" \"rossler\" \"simple_random_shuffle\" \"ornstein-uhlenbeck\")\n",
    "\n",
    "if [ ! -d \"$BASE_DIR\" ]; then\n",
    "  mkdir \"$BASE_DIR\"\n",
    "fi\n",
    "\n",
    "create_subfolders() {\n",
    "  local parent_dir=$1\n",
    "  for subfolder in \"${SUBFOLDERS[@]}\"; do\n",
    "    if [ ! -d \"$parent_dir/$subfolder\" ]; then\n",
    "      mkdir -p \"$parent_dir/$subfolder\"\n",
    "    fi\n",
    "  done\n",
    "}\n",
    "\n",
    "for subdir in \"${SUBDIRS[@]}\"; do\n",
    "  target_dir=\"$BASE_DIR/$subdir\"\n",
    "  if [ ! -d \"$target_dir\" ]; then\n",
    "    mkdir \"$target_dir\"\n",
    "  fi\n",
    "  create_subfolders \"$target_dir\"\n",
    "done\n",
    "\n",
    "echo \"Directory structure of graphics initialized.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports + Configurable Settings\n",
    "## Note\n",
    "You can assign global variables in this stage after the imports are finished."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Man6s3aqDteN"
   },
   "outputs": [],
   "source": [
    "# import arrayfire as af\n",
    "import gc\n",
    "import gzip\n",
    "import importlib\n",
    "import json\n",
    "import librosa\n",
    "import math\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import pprint\n",
    "import random\n",
    "import requests\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import soundfile as sf\n",
    "import subprocess\n",
    "import tarfile\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import visualkeras\n",
    "\n",
    "from brian2 import *\n",
    "from brian2hears import *\n",
    "from collections import deque\n",
    "from datetime import datetime\n",
    "from IPython.display import HTML\n",
    "from itertools import cycle\n",
    "from matplotlib import cm, colors\n",
    "from matplotlib.colors import to_rgba\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.manifold import TSNE\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras import backend as K, layers, models, callbacks\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape, Conv1D, Conv1DTranspose, Conv2D, Conv2DTranspose, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm import tqdm\n",
    "from types import NoneType\n",
    "from typing import Union, List, Tuple, Dict, Any\n",
    "from wave import Wave_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### configurable parameters\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "workingdirectory = '/content/'\n",
    "audiosampledir = 'Model/macleod/'\n",
    "graphpaths = 'Model/graphics'\n",
    "arraydir = 'Model/preprocessed_arrays'\n",
    "urlstxtdir = ''\n",
    "incompetechurl = 'https://incompetech.com/music/royalty-free/mp3-royaltyfree/'\n",
    "font_dirs = [\"/usr/local/share/fonts/truetype\"]\n",
    "\n",
    "font_files = fm.findSystemFonts(fontpaths=font_dirs)\n",
    "for font_file in font_files:\n",
    "    fm.fontManager.addfont(font_file)\n",
    "font_check = fm.get_font_names()\n",
    "plt.rcParams['font.family'] = 'Fira Sans'\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "\n",
    "# af.set_backend(\"cuda\")\n",
    "importlib.reload(filterbanklibrary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keQTudI1p7nE"
   },
   "outputs": [],
   "source": [
    "# Preprocessing Function defintions\n",
    "def extract_data_arrays(\n",
    "    sampled_data: Dict[str, Dict[str, Dict[str, ArrayContainer]]],\n",
    "    file_id: str = None,\n",
    "    processing_type: str = 'original',\n",
    "    component_type: str = 'real'\n",
    ") -> np.ndarray:\n",
    "\n",
    "    data_arrays = []\n",
    "\n",
    "    def extract_from_container(container: ArrayContainer) -> List[np.ndarray]:\n",
    "        \"\"\"Extracts arrays from a list, tuple, or dict.\"\"\"\n",
    "        if isinstance(container, (list, tuple)):\n",
    "            return [data for data in container]\n",
    "        elif isinstance(container, dict):\n",
    "            return [data for key, data in container.items()]\n",
    "        else:\n",
    "            print(f\"Expected a list, tuple, or dict but got {type(container)}\")\n",
    "            return []\n",
    "\n",
    "    def fetch_data_for_file(fid: str) -> List[np.ndarray]:\n",
    "        if fid in sampled_data:\n",
    "            file_data = sampled_data[fid]\n",
    "            if processing_type in file_data:\n",
    "                process_data = file_data[processing_type]\n",
    "                if component_type in process_data:\n",
    "                    bins = process_data[component_type]\n",
    "                    return extract_from_container(bins)\n",
    "                else:\n",
    "                    print(f\"Component type '{component_type}' not found for file ID '{fid}'.\")\n",
    "            else:\n",
    "                print(f\"Processing type '{processing_type}' not found for file ID '{fid}'.\")\n",
    "        else:\n",
    "            print(f\"File ID '{fid}' not found in data.\")\n",
    "        return []\n",
    "\n",
    "    if file_id:\n",
    "        data_arrays.extend(fetch_data_for_file(file_id))\n",
    "    else:\n",
    "        for fid in sampled_data.keys():\n",
    "            data_arrays.extend(fetch_data_for_file(fid))\n",
    "\n",
    "    if not data_arrays:\n",
    "        print(f\"No data arrays were extracted for '{processing_type}' and '{component_type}'. Check your input data.\")\n",
    "\n",
    "    return np.array(data_arrays)\n",
    "\n",
    "def extract_and_save_data_arrays_with_timestamp(\n",
    "    sampled_data: Dict[str, Dict[str, Dict[str, ArrayContainer]]],\n",
    "    directory=save_path[0]\n",
    ") -> str:\n",
    "\n",
    "    data_arrays = []\n",
    "    metadata = {'keys': [], 'processing_types': [], 'component_types': [], 'bin_ids': []}\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    timestamp = str(int(time.time()))\n",
    "    arrays_filename = os.path.join(directory, f'saved_arrays_{timestamp}.npz')\n",
    "    metadata_filename = os.path.join(directory, f'metadata_{timestamp}.json')\n",
    "    for key, proc_data in sampled_data.items():\n",
    "        for proc_type, comp_data in proc_data.items():\n",
    "            for comp_type, bins in comp_data.items():\n",
    "                for bin_id, array in bins.items():\n",
    "                    data_arrays.append(array)\n",
    "                    metadata['keys'].append(key)\n",
    "                    metadata['processing_types'].append(proc_type)\n",
    "                    metadata['component_types'].append(comp_type)\n",
    "                    metadata['bin_ids'].append(bin_id)\n",
    "    np.savez_compressed(arrays_filename, *data_arrays)\n",
    "    with open(metadata_filename, 'w') as meta_file:\n",
    "        json.dump(metadata, meta_file)\n",
    "\n",
    "    return metadata_filename, timestamp\n",
    "\n",
    "def load_and_rebuild_structure(metadata_filename: str, arrays_filename: str):\n",
    "    with open(metadata_filename, 'r') as meta_file:\n",
    "        metadata = json.load(meta_file)\n",
    "\n",
    "    array_data = np.load(arrays_filename)\n",
    "\n",
    "    reconstructed_data = {}\n",
    "    array_index = 0\n",
    "    for key, proc_type, comp_type, bin_id in zip(metadata['keys'], metadata['processing_types'], metadata['component_types'], metadata['bin_ids']):\n",
    "        if key not in reconstructed_data:\n",
    "            reconstructed_data[key] = {}\n",
    "        if proc_type not in reconstructed_data[key]:\n",
    "            reconstructed_data[key][proc_type] = {}\n",
    "        if comp_type not in reconstructed_data[key][proc_type]:\n",
    "            reconstructed_data[key][proc_type][comp_type] = {}\n",
    "        reconstructed_data[key][proc_type][comp_type][bin_id] = array_data[f'arr_{array_index}']\n",
    "        array_index += 1\n",
    "    return reconstructed_data\n",
    "\n",
    "def colab_write_frequency_bins_to_wav_and_archive(filter_outputs, file_path, sample_rate):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    directory = f\"{os.path.splitext(file_path)[0]}_iirexport_{timestamp}\"\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    if 'original' in filter_outputs and isinstance(filter_outputs['original'], dict):\n",
    "        nested_dict = filter_outputs['original']\n",
    "        num_filters = None\n",
    "        concatenated_frames = {}\n",
    "        for bin_key, waveform in nested_dict.items():\n",
    "            if isinstance(waveform, np.ndarray):\n",
    "                if num_filters is None:\n",
    "                    num_filters = waveform.shape[1]\n",
    "                    concatenated_frames = {f\"filter_{i}\": [] for i in range(num_filters)}\n",
    "                for i in range(num_filters):\n",
    "                    concatenated_frames[f\"filter_{i}\"].append(waveform[:, i])\n",
    "        for filter_index in range(num_filters):\n",
    "            concatenated_waveform = np.concatenate(concatenated_frames[f\"filter_{filter_index}\"])\n",
    "            filename = f\"{directory}/filter_{filter_index+1:03d}_{timestamp}.wav\"\n",
    "            sf.write(filename, concatenated_waveform, sample_rate)\n",
    "            print(f\"Written WAV file for filter {filter_index+1:03d}\")\n",
    "    else:\n",
    "        print(\"Expected 'original' key with a dictionary of numpy arrays. Structure not found.\")\n",
    "    tarball_name = f\"{directory}.tar.gz\"\n",
    "    os.system(f\"tar -czf '{tarball_name}' -C '{directory}' .\")\n",
    "    print(f\"Tarball created: {tarball_name}\")\n",
    "    os.system(f\"rm -r '{directory}'\")\n",
    "\n",
    "## FFMPEG SUBPROCESSES\n",
    "def convert_to_mp3_and_back(input_wav_path, output_wav_path, bitrate='32k', file_sr=44100):\n",
    "    temp_mp3 = tempfile.NamedTemporaryFile(suffix='.mp3', delete=False)\n",
    "    command_mp3 = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', input_wav_path,\n",
    "        '-codec:a', 'libmp3lame',\n",
    "        '-b:a', bitrate,\n",
    "        temp_mp3.name\n",
    "    ]\n",
    "    subprocess.run(command_mp3, check=True)\n",
    "\n",
    "    command_wav = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', temp_mp3.name,\n",
    "        '-acodec', 'pcm_s16le',\n",
    "        '-ar', str(file_sr),\n",
    "        output_wav_path\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command_wav, check=True)\n",
    "    temp_mp3.close()\n",
    "\n",
    "def prepare_audio_files(file_path, duration, UseDualMono=True):\n",
    "    try:\n",
    "        probe_command = ['ffprobe', '-v', 'error', '-select_streams', 'a:0', '-show_entries', 'stream=channels', '-of', 'default=noprint_wrappers=1:nokey=1', file_path]\n",
    "        probe_result = subprocess.run(probe_command, text=True, capture_output=True)\n",
    "        if probe_result.returncode != 0:\n",
    "            print(\"Error probing the file:\", probe_result.stderr)\n",
    "            return []\n",
    "        channels = int(probe_result.stdout.strip())\n",
    "        print(f\"Detected {channels} channels.\")\n",
    "        base_name = os.path.splitext(file_path)[0]\n",
    "        temp_files = []\n",
    "        if channels == 2:\n",
    "            if UseDualMono:\n",
    "                channel_labels = ['_L', '_R']\n",
    "            else:\n",
    "                channel_labels = [random.choice(['_L', '_R'])]\n",
    "\n",
    "            for i, label in enumerate(channel_labels):\n",
    "                output_file = f\"{base_name}{label}.wav\"\n",
    "                command = [\n",
    "                    'ffmpeg', '-y', '-i', file_path,\n",
    "                    '-map_channel', f'0.0.{0 if label == \"_L\" else 1}',\n",
    "                    '-acodec', 'pcm_s16le',\n",
    "                    '-ar', '44100',\n",
    "                    '-ac', '1',\n",
    "                    '-t', str(duration),\n",
    "                    output_file\n",
    "                ]\n",
    "                print(\"Running command:\", ' '.join(command))\n",
    "                subprocess_result = subprocess.run(command, text=True, capture_output=True)\n",
    "                if subprocess_result.returncode != 0:\n",
    "                    print(\"ffmpeg error:\", subprocess_result.stderr)\n",
    "                    continue\n",
    "                temp_files.append(output_file)\n",
    "\n",
    "        elif channels == 1:  # Mono file, standardize format and return\n",
    "            output_file = f\"{base_name}_mono.wav\"\n",
    "            command = [\n",
    "                'ffmpeg', '-y', '-i', file_path,\n",
    "                '-acodec', 'pcm_s16le',\n",
    "                '-ar', '44100',\n",
    "                '-ac', '1',\n",
    "                '-t', str(duration),\n",
    "                output_file\n",
    "            ]\n",
    "            subprocess_result = subprocess.run(command, text=True, capture_output=True)\n",
    "            if subprocess_result.returncode == 0:\n",
    "                temp_files.append(output_file)\n",
    "        return temp_files\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "def cochlear_iir(file_path, fft_size=256, downloadfile=False, rectify=True, min_frequency=20, max_frequency=20000, num_frequency_bins=100, bw=None, random_order=False, with_lossy_backprop=False, *args, **kwargs):\n",
    "    y, file_sr = librosa.load(file_path, sr=None, )\n",
    "    brainload = loadsound(f\"{file_path}\")  # Ensure load is capable of reading from file path\n",
    "    num_frames_original = int(np.ceil(len(y) / fft_size))\n",
    "    total_frames = num_frames_original * (2 if with_lossy_backprop else 1)\n",
    "    print(f\"now passing file: {file_path} through filterbank...\")\n",
    "    global center_frequencies\n",
    "    center_frequencies = erbspace(min_frequency*Hz, max_frequency*Hz, num_frequency_bins)\n",
    "    if rectify:\n",
    "              brainload = FunctionFilterbank(brainload, lambda x: clip(x, 0, Inf)**(1.0/3.0))\n",
    "    if bw is None:\n",
    "        bw = 10**(0.037 + 0.785 * np.log10(center_frequencies / Hz))\n",
    "    def process_audio(audio_data, audio_brain, num_frames, file_sr):\n",
    "        filter_outputs = {}\n",
    "        try:\n",
    "            gammatone = ApproximateGammatone(audio_brain, center_frequencies, bw, 4, use_individual_outputs=True)\n",
    "            framefilter = gammatone.process(buffersize=fft_size)\n",
    "            for i in range(num_frames):\n",
    "                start_sample = i * fft_size\n",
    "                end_sample = min(start_sample + fft_size, framefilter.shape[0])\n",
    "                frame = framefilter[start_sample:end_sample]\n",
    "                if len(frame) < fft_size:  # zero-pad if necessary\n",
    "                    frame = np.pad(frame, ((0, fft_size - len(frame)), (0, 0)), mode='constant')\n",
    "                filter_outputs[f'bin_{i}'] = frame\n",
    "        except Exception as e:\n",
    "            print(\"Error during processing:\", e)\n",
    "        print(f'Type of filter_outputs: {type(filter_outputs)}') #dictionary\n",
    "        return filter_outputs\n",
    "    results = {'original': process_audio(y, brainload, num_frames_original, file_sr)}\n",
    "\n",
    "    if downloadfile:\n",
    "        colab_write_frequency_bins_to_wav_and_archive(results, file_path, file_sr)\n",
    "\n",
    "    if with_lossy_backprop:\n",
    "        temp_wav_path = file_path.replace('.wav', '_temp.wav')\n",
    "        output_wav_path = file_path.replace('.wav', '_back_from_mp3.wav')\n",
    "        convert_to_mp3_and_back(file_path, output_wav_path, bitrate='64k', file_sr=file_sr)\n",
    "        y_lossy, _ = librosa.load(output_wav_path, sr=file_sr)\n",
    "        brianload = loadsound(f\"{output_wav_path}\")\n",
    "        results['lossy'] = process_audio(y_lossy, brainload, num_frames_original, file_sr)\n",
    "        os.remove(output_wav_path)  # Clean up\n",
    "\n",
    "    return results\n",
    "\n",
    "def epochset(file_paths, *args, **kwargs):\n",
    "    results = {}\n",
    "    filename_mapping = {}\n",
    "    outputs = {}\n",
    "    new_file_paths = []\n",
    "    with_lossy_backprop = kwargs.get('with_lossy_backprop', False)\n",
    "    backend = kwargs.get('backend', \"pytorch\")\n",
    "    duration = kwargs.get('duration', 60)\n",
    "    UseDualMono = kwargs.get('UseDualMono', True)\n",
    "    for file_path in file_paths:\n",
    "        temp_files = prepare_audio_files(file_path, duration, UseDualMono)\n",
    "        if not temp_files:\n",
    "            continue\n",
    "        new_file_path = temp_files[0]  # assume the first file is what we need\n",
    "        new_file_paths.append(new_file_path)\n",
    "        normalized_name = normalize_filename(new_file_path)\n",
    "        filename_mapping[file_path] = normalized_name\n",
    "        outputs = cochlear_iir(new_file_path, *args, **kwargs)\n",
    "        for processing_type in outputs:\n",
    "            key = f\"{processing_type}_{normalized_name}\"\n",
    "            print(f\"now performing discrete fourier transform series for key: {normalized_name}...\")\n",
    "            print(f\"performing calculations on {processing_type} version of the original file...\")\n",
    "            results[key] = perform_dft(outputs[processing_type], **kwargs)\n",
    "    return results, filename_mapping, new_file_paths, outputs  # we return the filtered outputs\n",
    "\n",
    "def perform_dft(named_arrays, with_lossy_backprop=False, progress_meter=None, backend='pytorch', **kwargs):\n",
    "    if isinstance(named_arrays, list):\n",
    "        named_arrays = {f'bin_{i}': named_arrays[i] for i in range(len(named_arrays))}\n",
    "\n",
    "    if progress_meter is None:\n",
    "        total_length = sum(len(data) for data in named_arrays.values())\n",
    "        progress_meter = tqdm(total=total_length, desc='DFTs per second', unit='DFTs', leave=True, position=0)\n",
    "\n",
    "    dfts_for_network = {'real': {}, 'imaginary': {}}\n",
    "\n",
    "    def get_target_length(frames):\n",
    "        return max(len(frame) for frame in frames)\n",
    "\n",
    "    def pad_or_trim_frame(frame, target_length):\n",
    "        if len(frame) > target_length:\n",
    "            return frame[:target_length]\n",
    "        else:\n",
    "            padding = target_length - len(frame)\n",
    "            if isinstance(frame, torch.Tensor):\n",
    "                return torch.cat((frame, torch.zeros(padding, dtype=frame.dtype, device=frame.device)), dim=0)\n",
    "            else:\n",
    "                return np.pad(frame, (0, padding), 'constant')\n",
    "\n",
    "    def process_with_pytorch(frames, use_gpu):\n",
    "        target_length = get_target_length(frames)\n",
    "        if use_gpu:\n",
    "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            device = torch.device('cpu')\n",
    "        padded_frames = [pad_or_trim_frame(torch.tensor(frame, dtype=torch.complex64, device=device), target_length) for frame in frames]\n",
    "        stacked_frames = torch.stack(padded_frames)\n",
    "        dft_results = torch.fft.fft(stacked_frames)\n",
    "        real_parts = torch.real(dft_results).cpu().numpy()  # Ensure transfer back to CPU for compatibility with numpy\n",
    "        imaginary_parts = torch.imag(dft_results).cpu().numpy()\n",
    "\n",
    "        progress_meter.update(len(frames))\n",
    "        return real_parts, imaginary_parts\n",
    "\n",
    "    def process_with_arrayfire(frames):\n",
    "        real_parts = []\n",
    "        imaginary_parts = []\n",
    "        target_length = get_target_length(frames)\n",
    "        frames = np.array(frames) if not isinstance(frames, np.ndarray) else frames\n",
    "        for frame in frames:\n",
    "            frame = pad_or_trim_frame(frame, target_length)\n",
    "            af_array = af.interop.from_ndarray(frame)\n",
    "            dft_result = af.dft(af_array)\n",
    "            real_parts.append(np.real(dft_result.to_ndarray()))\n",
    "            imaginary_parts.append(np.imag(dft_result.to_ndarray()))\n",
    "            progress_meter.update(1)\n",
    "        return np.stack(real_parts), np.stack(imaginary_parts)\n",
    "\n",
    "    def process_with_tensorflow(frames):\n",
    "        real_parts = []\n",
    "        imaginary_parts = []\n",
    "        target_length = get_target_length(frames)\n",
    "        frames = np.array(frames) if not isinstance(frames, np.ndarray) else frames\n",
    "        for frame in frames:\n",
    "            frame = pad_or_trim_frame(frame, target_length)\n",
    "            frame_tensor = tf.convert_to_tensor(frame, dtype=tf.complex64)\n",
    "            dft_result = tf.signal.fft(frame_tensor)\n",
    "            real_parts.append(tf.math.real(dft_result).numpy())\n",
    "            imaginary_parts.append(tf.math.imag(dft_result).numpy())\n",
    "            progress_meter.update(1)\n",
    "        return np.stack(real_parts), np.stack(imaginary_parts)\n",
    "\n",
    "    for key, frames in named_arrays.items():\n",
    "        if backend == 'pytorch':\n",
    "            use_gpu = kwargs.get('use_gpu', \"False\")\n",
    "            real_parts, imaginary_parts = process_with_pytorch(frames, use_gpu=use_gpu)\n",
    "        elif backend == 'tensorflow':\n",
    "            real_parts, imaginary_parts = process_with_tensorflow(frames)\n",
    "        elif backend == 'pytorch':\n",
    "            real_parts, imaginary_parts = process_with_pytorch(frames)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported backend: {backend}\")\n",
    "        dfts_for_network['real'][key] = real_parts\n",
    "        dfts_for_network['imaginary'][key] = imaginary_parts\n",
    "\n",
    "    progress_meter.close()\n",
    "\n",
    "    if backend == 'tensorflow':\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "\n",
    "    if backend == 'pytorch' and use_gpu:\n",
    "        torch.cuda.empty_cache()  # clear gpus after processing\n",
    "\n",
    "    return dfts_for_network\n",
    "\n",
    "def configure_epochs(file_paths, num_bins=None, fft_size=256, ignore_temporality=False, *args, **kwargs):\n",
    "    full_results, filename_mapping, new_file_paths, outputs = epochset(file_paths, fft_size=fft_size, *args, **kwargs)\n",
    "    epoch_data = {}\n",
    "\n",
    "    for file_path, normalized_name in filename_mapping.items():\n",
    "        for key in [f\"original_{normalized_name}\", f\"lossy_{normalized_name}\"]:\n",
    "            if key in full_results:\n",
    "                dfts = full_results[key]\n",
    "                if normalized_name not in epoch_data:\n",
    "                    epoch_data[normalized_name] = {}\n",
    "                if 'original' in key:\n",
    "                    processing_type = 'original'\n",
    "                else:\n",
    "                    processing_type = 'lossy'\n",
    "\n",
    "                epoch_data[normalized_name][processing_type] = {'real': {}, 'imaginary': {}}\n",
    "                for component_type in ['real', 'imaginary']:\n",
    "                    if component_type in dfts:\n",
    "                        bin_limit = num_bins.get(normalized_name, None) if num_bins else None\n",
    "                        for bin_key, values in dfts[component_type].items():\n",
    "                            if 'bin' in bin_key:\n",
    "                                bin_index = int(bin_key.split('_')[-1])\n",
    "                                if bin_limit is None or bin_index < bin_limit:\n",
    "                                    epoch_data[normalized_name][processing_type][component_type][bin_key] = values\n",
    "\n",
    "    if ignore_temporality:\n",
    "        for basename in epoch_data:\n",
    "            for processing_type in epoch_data[basename]:\n",
    "                for component_type in ['real', 'imaginary']:\n",
    "                    bin_keys = list(epoch_data[basename][processing_type][component_type].keys())\n",
    "                    random.shuffle(bin_keys)\n",
    "                    shuffled_bins = {key: epoch_data[basename][processing_type][component_type][key] for key in bin_keys}\n",
    "                    epoch_data[basename][processing_type][component_type] = shuffled_bins\n",
    "\n",
    "    return epoch_data, outputs\n",
    "\n",
    "def normalize_filename(file_path):\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    normalized_name = base_name.replace(' ', '_').replace('-', '_').lower()\n",
    "    return normalized_name\n",
    "\n",
    "def append_dataset(directory):\n",
    "    file_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            full_path = os.path.join(root, file)\n",
    "            if len(file_list) % 2 == 0:\n",
    "                file_list.append(f\"{full_path}\")\n",
    "            else:\n",
    "                file_list.append(f'{full_path}')\n",
    "    return file_list\n",
    "\n",
    "def macleodchance(file_path, sample_size):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    lines = [line.strip() for line in lines if line.strip()]\n",
    "    sampled_lines = random.sample(lines, min(sample_size, len(lines)))\n",
    "    return sampled_lines\n",
    "\n",
    "def macleodownload(base_url, paths, directory):\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    for path in paths:\n",
    "        url = base_url + path\n",
    "        file_name = path\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            print(f\"Downloaded {url} to {file_path}\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Failed to download {url}. Error: {e}\")\n",
    "\n",
    "def nab_fileids(sampled_data):\n",
    "    filearr = []\n",
    "    for file_id, processing_types in sampled_data.items():\n",
    "        filearr.append(file_id)\n",
    "    return filearr\n",
    "\n",
    "def save_svg(fig, filename):\n",
    "    output_dir = '/content/Model/graphics'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    fig.savefig(os.path.join(output_dir, f'{filename}.svg'), format='svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Processes + Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrC_LrEcliOy"
   },
   "outputs": [],
   "source": [
    "### Kamada-Kawai Helpers using dijekstra lengths (for gpu acceleration)\n",
    "class KamadaKawaiOptimizer(nn.Module):\n",
    "    def __init__(self, D, K):\n",
    "        super(KamadaKawaiOptimizer, self).__init__()\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "        self.pos = nn.Parameter(torch.rand(D.shape[0], 2))\n",
    "\n",
    "    def forward(self):\n",
    "        dist = torch.cdist(self.pos, self.pos, p=2)\n",
    "        delta = self.D - dist\n",
    "        energy = 0.5 * torch.sum(self.K * delta**2)\n",
    "        return energy\n",
    "\n",
    "def compute_kamada_kawai_positions(D, K, num_epochs=1000, learning_rate=0.01):\n",
    "    model = KamadaKawaiOptimizer(D, K)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model.pos.detach().numpy()\n",
    "\n",
    "def initialize_kamada_kawai_layout(G, num_epochs=1000, learning_rate=0.01):\n",
    "    num_nodes = G.number_of_nodes()\n",
    "    D = np.zeros((num_nodes, num_nodes))\n",
    "    K = np.zeros((num_nodes, num_nodes))\n",
    "\n",
    "    lengths = dict(nx.all_pairs_dijkstra_path_length(G))\n",
    "\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(num_nodes):\n",
    "            if i != j:\n",
    "                D[i, j] = lengths[i][j]\n",
    "                K[i, j] = 1 / D[i, j]**2\n",
    "\n",
    "    D = torch.tensor(D, dtype=torch.float32)\n",
    "    K = torch.tensor(K, dtype=torch.float32)\n",
    "\n",
    "    return compute_kamada_kawai_positions(D, K, num_epochs=num_epochs, learning_rate=learning_rate)\n",
    "\n",
    "#### ^^ OPtionAL\n",
    "### Helpers:\n",
    "def create_color_mapping(file_ids, cmap_name='tab10'):\n",
    "    color_cycle = plt.get_cmap(cmap_name).colors  # Get color cycle from colormap\n",
    "    color_iterator = cycle(color_cycle)  # Create an iterator that cycles through the colors\n",
    "    file_id_to_color = {file_id: next(color_iterator) for file_id in file_ids}\n",
    "    return file_id_to_color\n",
    "\n",
    "def get_sorted_bin_keys(data):\n",
    "    # Extract keys and sort them based on the numerical suffix\n",
    "    bin_keys = list(data.keys())\n",
    "    bin_keys.sort(key=lambda x: int(re.search(r'\\d+', x).group()))\n",
    "    return bin_keys\n",
    "\n",
    "### sampling functions and logging functions\n",
    "def print_initial_bin_counts(sampled_data, epoch_data, cross_file_sampling, file_ids):\n",
    "    if cross_file_sampling:\n",
    "        print(\"Initial bin counts:\")\n",
    "        for processing_type in ['original', 'lossy']:\n",
    "            for component_type in ['real', 'imaginary']:\n",
    "                bins_count = sum([len(epoch_data[file_id][processing_type][component_type]) for file_id in file_ids])\n",
    "                print(f\"{processing_type.capitalize()} - {component_type.capitalize()}: {bins_count} bins\")\n",
    "    else:\n",
    "        for file_id in file_ids:\n",
    "            print(f\"Initial bin counts for file_id: {file_id}\")\n",
    "            for processing_type in ['original', 'lossy']:\n",
    "                for component_type in ['real', 'imaginary']:\n",
    "                    bins_count = len(epoch_data[file_id][processing_type][component_type])\n",
    "                    print(f\"{processing_type.capitalize()} - {component_type.capitalize()}: {bins_count} bins\")\n",
    "\n",
    "def print_final_bin_counts(sampled_data, cross_file_sampling, file_ids):\n",
    "    if cross_file_sampling:\n",
    "        print(\"Final bin counts:\")\n",
    "        for processing_type in ['original', 'lossy']:\n",
    "            for component_type in ['real', 'imaginary']:\n",
    "                bins = list(sampled_data['total_list'][processing_type][component_type].keys())\n",
    "                print(f\"{processing_type.capitalize()} - {component_type.capitalize()}: {len(bins)} unique bins, containing: {bins}\")\n",
    "    else:\n",
    "        for file_id in file_ids:\n",
    "            print(f\"Final bin counts for file_id: {file_id}\")\n",
    "            for processing_type in ['original', 'lossy']:\n",
    "                for component_type in ['real', 'imaginary']:\n",
    "                    bins = list(sampled_data[file_id][processing_type][component_type].keys())\n",
    "                    print(f\"{processing_type.capitalize()} - {component_type.capitalize()}: {len(bins)} unique bins, containing: {bins}\")\n",
    "\n",
    "def stochastic_process(method, unique_bins_list, num_samples, bin_min, bin_max, **params):\n",
    "    methods = {\n",
    "        'simple_random_shuffle': simple_random_shuffle,\n",
    "        'ornstein-uhlenbeck': ornstein_uhlenbeck_process,\n",
    "        'maximal_entropy': maximal_entropy_process,\n",
    "        'rossler': rossler_process\n",
    "    }\n",
    "\n",
    "    method_func = methods.get(method)\n",
    "\n",
    "    if not method_func:\n",
    "        raise ValueError(f\"Sampling method '{method}' not recognized\")\n",
    "    return method_func(unique_bins_list, num_samples, bin_min, bin_max, **params)\n",
    "\n",
    "def simple_random_shuffle(unique_bins_list, num_samples, bin_min, bin_max, **params):\n",
    "    np.random.shuffle(unique_bins_list)\n",
    "    indices = np.arange(min(num_samples, len(unique_bins_list)))\n",
    "    return indices, None\n",
    "\n",
    "### OU Process + Animators\n",
    "def ornstein_uhlenbeck(start, num_samples, mean, scale, theta, dt=1):\n",
    "    \"\"\"Generates path from a starting point.\"\"\"\n",
    "    if num_samples <= 0:\n",
    "        raise ValueError(\"num_samples must be a positive integer\")\n",
    "    path = np.zeros(num_samples)\n",
    "    path[0] = start\n",
    "    for i in range(1, num_samples):\n",
    "        drift = theta * (mean - path[i-1]) * dt\n",
    "        randomness = scale * np.random.normal()\n",
    "        path[i] = path[i-1] + drift + randomness\n",
    "    return path\n",
    "\n",
    "def ornstein_uhlenbeck_process(unique_bins_list, num_samples, bin_min, bin_max, randomize=False, **params):\n",
    "    # Unpack parameters with defaults and randomization if needed\n",
    "    start = params.get('start', random.uniform(bin_min, bin_max) if randomize else 0)\n",
    "    mean = params.get('mean', random.uniform(bin_min, bin_max) if randomize else (bin_min + bin_max) / 2)\n",
    "    scale = params.get('scale', random.uniform(0.1, 2.0) if randomize else 1)\n",
    "    theta = params.get('theta', random.uniform(0.05, 0.3) if randomize else 0.15)\n",
    "    dt = params.get('dt', random.uniform(0.01, 1.0) if randomize else 1)\n",
    "\n",
    "    path = ornstein_uhlenbeck(start, num_samples, mean, scale, theta, dt)\n",
    "    indices = np.clip(path, bin_min, bin_max).astype(int)\n",
    "    if params.get('visualize', False):\n",
    "        animation = animate_ornstein_uhlenbeck(path, num_samples)\n",
    "        html_video = HTML(animation.to_html5_video())\n",
    "        return indices, html_video\n",
    "\n",
    "    return indices, None\n",
    "\n",
    "def animate_ornstein_uhlenbeck(ou_path, num_samples, fps=30):\n",
    "    \"\"\"Animate the Ornstein-Uhlenbeck process using a given path and save the last frame as an SVG.\"\"\"\n",
    "    global graphics_path\n",
    "    time_constant = 0.09287981859410431\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    line, = ax.plot([], [], 'r-', label='OU Process')\n",
    "    point, = ax.plot([], [], 'ro')\n",
    "\n",
    "    ax.set_xlim(0, num_samples - 1)\n",
    "    ax.set_ylim(min(ou_path), max(ou_path))\n",
    "    ax.legend()\n",
    "\n",
    "    ax.set_xlabel('bin # in sequence')\n",
    "    ax.set_ylabel(f'time (s)')\n",
    "    ax.set_title('Ornstein-Uhlenbeck Process Example')\n",
    "\n",
    "    def init():\n",
    "        line.set_data(range(num_samples), ou_path)\n",
    "        point.set_data([], [])\n",
    "        return line, point,\n",
    "\n",
    "    def animate(i):\n",
    "        point.set_data(i, ou_path[i])\n",
    "        if i == num_samples - 1:\n",
    "            fig.savefig(os.path.join(f'{graphics_path}/ornstein-uhlenbeck', 'ou_last_frame.svg'), format='svg', transparent=True, bbox_inches='tight')\n",
    "        return line, point,\n",
    "\n",
    "    os.makedirs(graphics_path, exist_ok=True)  # Ensure the directory exists\n",
    "    ani = animation.FuncAnimation(fig, animate, init_func=init, frames=num_samples, interval=1000 / fps, blit=True)\n",
    "    ani.save(os.path.join(f'{graphics_path}/ornstein-uhlenbeck', 'ou_animation.mp4'), writer='ffmpeg', fps=fps)\n",
    "    plt.close(fig)\n",
    "    return ani\n",
    "### rossler process + animators\n",
    "\n",
    "def random_color():\n",
    "    \"\"\"Generate a random color.\"\"\"\n",
    "    return np.random.rand(3,)\n",
    "\n",
    "def sanitize(value, default=0.0):\n",
    "    \"\"\"Sanitize a value to ensure it is a finite real number.\"\"\"\n",
    "    if not np.isfinite(value):\n",
    "        return default\n",
    "    return value\n",
    "\n",
    "def rossler_attractor(start, num_samples, a, b, c, dt):\n",
    "    x, y, z = start\n",
    "    path_x = [x]\n",
    "    path_y = [y]\n",
    "    path_z = [z]\n",
    "    for _ in range(num_samples - 1):\n",
    "        dx = -y - z\n",
    "        dy = x + a * y\n",
    "        dz = b + z * (x - c)\n",
    "        x += dx * dt\n",
    "        y += dy * dt\n",
    "        z += dz * dt\n",
    "        path_x.append(x)\n",
    "        path_y.append(y)\n",
    "        path_z.append(z)\n",
    "    return np.array([path_x, path_y, path_z]).T\n",
    "\n",
    "def rossler_process(unique_bins_list, num_samples, bin_min, bin_max, randomize=False, **params):\n",
    "    retries = 500\n",
    "    while retries > 0:\n",
    "        if randomize:\n",
    "            start = (\n",
    "                sanitize(random.uniform(bin_min, bin_max)),\n",
    "                sanitize(random.uniform(-10, 10)),\n",
    "                sanitize(random.uniform(-10, 10))\n",
    "            )\n",
    "            a = sanitize(random.uniform(0.5, 2.0))\n",
    "            b = sanitize(random.uniform(0.5, 3.0))\n",
    "            c = sanitize(random.uniform(0.1, 1.5))\n",
    "            dt = sanitize(random.uniform(0.01, 0.1))\n",
    "        else:\n",
    "            start = (bin_min, 0, 0)\n",
    "            a = 1.2\n",
    "            b = 1.8\n",
    "            c = 0.7\n",
    "            dt = 0.04\n",
    "\n",
    "        r_params = sanitize_params({\n",
    "            'start': start,\n",
    "            'num_samples': num_samples,\n",
    "            'a': a,\n",
    "            'b': b,\n",
    "            'c': c,\n",
    "            'dt': dt,\n",
    "        })\n",
    "\n",
    "        process_path = rossler_attractor(**r_params)\n",
    "        z_component = process_path[:, 2]\n",
    "\n",
    "        # Check if process_path is valid\n",
    "        if np.all(np.isfinite(process_path)) and np.any(z_component != 0):\n",
    "            normalized_indices = (z_component - np.min(z_component)) / (np.max(z_component) - np.min(z_component))\n",
    "            indices = np.clip((normalized_indices * (bin_max - bin_min) + bin_min).astype(int), 0, bin_max)\n",
    "\n",
    "            if params.get('visualize', False):\n",
    "                animation = animate_rossler(process_path, num_samples, indices, r_params)\n",
    "                return indices, animation\n",
    "\n",
    "            return indices, None\n",
    "\n",
    "        retries -= 1\n",
    "\n",
    "    raise ValueError(\"Failed to generate valid Rossler attractor parameters after multiple retries\")\n",
    "\n",
    "def animate_rossler(process_path, num_samples, indices, r_params):\n",
    "    \"\"\"Animate the Rössler attractor and save the last frame as an SVG.\"\"\"\n",
    "    global graphics_path\n",
    "    time_constant = 0.09287981859410431\n",
    "    x, y, z = process_path.T\n",
    "\n",
    "    # Sanitize limits to avoid NaN or Inf\n",
    "    x_min, x_max = sanitize(np.min(x), -1), sanitize(np.max(x), 1)\n",
    "    y_min, y_max = sanitize(np.min(y), -1), sanitize(np.max(y), 1)\n",
    "    z_min, z_max = sanitize(np.min(z), -1), sanitize(np.max(z), 1)\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    color_z = random_color()\n",
    "    color_x = random_color()\n",
    "    color_y = random_color()\n",
    "\n",
    "    line_z, = ax.plot([], [], [], lw=2, label='Z-component', color=color_z)\n",
    "    line_x, = ax.plot([], [], [], lw=1, label='X-component', color=color_x, alpha=0.5)\n",
    "    line_y, = ax.plot([], [], [], lw=1, label='Y-component', color=color_y, alpha=0.5)\n",
    "\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    ax.set_zlim([z_min, z_max])\n",
    "\n",
    "    ax.set_title('Rössler Attractor Animation')\n",
    "\n",
    "    # Create a second legend for the random parameters and time\n",
    "    param_legend_text = f\"Parameters:\\n\" \\\n",
    "                        f\"a = {r_params['a']:.2f}\\n\" \\\n",
    "                        f\"b = {r_params['b']:.2f}\\n\" \\\n",
    "                        f\"c = {r_params['c']:.2f}\\n\" \\\n",
    "                        f\"dt = {r_params['dt']:.2f}\\n\" \\\n",
    "                        f\"Time (s): {0:.2f}\"\n",
    "    param_legend = ax.text2D(0.05, 0.95, param_legend_text, transform=ax.transAxes, fontsize=10, verticalalignment='top', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    def init():\n",
    "        line_z.set_data([], [])\n",
    "        line_z.set_3d_properties([])\n",
    "        line_x.set_data([], [])\n",
    "        line_x.set_3d_properties([])\n",
    "        line_y.set_data([], [])\n",
    "        line_y.set_3d_properties([])\n",
    "        return line_z, line_x, line_y, param_legend\n",
    "\n",
    "    def animate(i):\n",
    "        global graphics_path\n",
    "        line_z.set_data(x[:i], y[:i])\n",
    "        line_z.set_3d_properties(z[:i])\n",
    "        line_x.set_data(x[:i], [0] * i)\n",
    "        line_x.set_3d_properties(z[:i])\n",
    "        line_y.set_data([0] * i, y[:i])\n",
    "        line_y.set_3d_properties(z[:i])\n",
    "\n",
    "        # Update the legend with the current time value\n",
    "        param_legend.set_text(f\"Parameters:\\n\"\n",
    "                              f\"a = {r_params['a']:.2f}\\n\"\n",
    "                              f\"b = {r_params['b']:.2f}\\n\"\n",
    "                              f\"c = {r_params['c']:.2f}\\n\"\n",
    "                              f\"dt = {r_params['dt']:.2f}\\n\"\n",
    "                              f\"Time (s): {indices[i] * time_constant:.2f}\")\n",
    "\n",
    "        if i == num_samples - 1:  # Save last frame\n",
    "            fig.savefig(os.path.join(f'{graphics_path}/rossler', 'rossler_last_frame.svg'), format='svg', transparent=True, bbox_inches='tight')\n",
    "        return line_z, line_x, line_y, param_legend\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, animate, init_func=init, frames=num_samples, interval=50, blit=True)\n",
    "    plt.close(fig)\n",
    "    output_dir = graphics_path\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    ani.save(os.path.join(f'{output_dir}/rossler', 'rossler_animation.mp4'), writer='ffmpeg', fps=30)\n",
    "\n",
    "    return ani\n",
    "\n",
    "### MERW + animators\n",
    "def maximal_entropy_process(unique_bins_list, num_samples, bin_min, bin_max, **params):\n",
    "    L = len(unique_bins_list)\n",
    "    print(f\"Total unique bins: {L}\")  # Debugging output\n",
    "    q = params.get('connectivity', 0.7)\n",
    "    G = initialize_irregular_lattice(L, q)\n",
    "    path = maximal_entropy_random_walk(G, L)\n",
    "    if G.number_of_edges() == 0:\n",
    "        print(\"Warning: No edges in the graph. Check connectivity parameter and node initialization.\")\n",
    "    if not path:\n",
    "        print(\"Warning: Random walk path is empty.\")\n",
    "    indices = path\n",
    "    if not indices:\n",
    "        print(\"Warning: No indices generated from the path.\")\n",
    "    if params.get('visualize', False):\n",
    "        animation = animate_random_walk(params, G, path, L, q)\n",
    "        return indices, animation\n",
    "    return indices, None\n",
    "\n",
    "def maximal_entropy_random_walk(G, num_samples):\n",
    "    A = nx.adjacency_matrix(G).todense()\n",
    "    evals, evecs = np.linalg.eigh(A)\n",
    "    lambda_max = np.max(evals)\n",
    "    psi = evecs[:, evals.argmax()]\n",
    "    psi_normalized = psi / np.linalg.norm(psi, ord=2)\n",
    "    P = np.zeros_like(A, dtype=float)\n",
    "    for i in range(len(G.nodes)):\n",
    "        for j in range(len(G.nodes)):\n",
    "            if A[i, j] > 0:\n",
    "                P[i, j] = (A[i, j] / lambda_max) * (psi_normalized[j] / psi_normalized[i])\n",
    "    P /= P.sum(axis=1, keepdims=True)  # Normalize the transition probability matrix\n",
    "    path = [np.random.randint(len(G.nodes))]\n",
    "    for _ in range(1, num_samples):\n",
    "        current = path[-1]\n",
    "        if np.any(np.isnan(P[current])):\n",
    "            raise ValueError(\"Transition probabilities contain NaN.\")\n",
    "        next_node = np.random.choice(len(G.nodes), p=P[current])\n",
    "        path.append(next_node)\n",
    "    return path\n",
    "\n",
    "def initialize_irregular_lattice(num_nodes, connectivity):\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i + 1, num_nodes):\n",
    "            if np.random.rand() < connectivity:\n",
    "                G.add_edge(i, j)\n",
    "    return G\n",
    "\n",
    "def animate_random_walk(params, G, path, L, q):\n",
    "    global graphics_path\n",
    "    num_samples = params.get('num_samples', 1500)\n",
    "    fps = params.get('fps', 30)  # frames per second\n",
    "    total_duration = params.get('total_duration', 50)  # duration of the animation in seconds\n",
    "    frames = fps * total_duration  # total frames shown in the animation\n",
    "    highest_step = min(frames, len(path) - 1)  # Highest step to determine color scale\n",
    "    pos = nx.kamada_kawai_layout(G)  # use gpu here if need\n",
    "    fig, ax = plt.subplots(figsize=(10, 12), dpi=300)  # Increased DPI for higher resolution\n",
    "    ax.set_xlim([min(p[0] for p in pos.values()) - 0.2, max(p[0] for p in pos.values()) + 0.2])\n",
    "    ax.set_ylim([min(p[1] for p in pos.values()) - 0.2, max(p[1] for p in pos.values()) + 0.2])\n",
    "    ax.set_title('Maximal Entropy Random Walk Visualization', fontsize=16, color='black')\n",
    "    # Edge and node setup\n",
    "    edge_list = list(G.edges())\n",
    "    edge_colors = [to_rgba('grey', alpha=0.10)] * len(edge_list)\n",
    "    edges = nx.draw_networkx_edges(G, pos, ax=ax, edgelist=edge_list, edge_color=edge_colors, width=1)\n",
    "    color_map = plt.get_cmap('plasma')\n",
    "    nodes = nx.draw_networkx_nodes(G, pos, ax=ax, node_color='grey', alpha=0.4, cmap=color_map, node_size=50)\n",
    "\n",
    "    visited = {}\n",
    "    node_color_values = np.zeros(L)\n",
    "    current_text = ax.text(0.05, 0.95, '', transform=ax.transAxes, color='black')\n",
    "\n",
    "    def update(num):\n",
    "        current_node = path[num]\n",
    "        if current_node not in visited:\n",
    "            visited[current_node] = num\n",
    "        for n in range(L):\n",
    "            node_color_values[n] = visited.get(n, 0) / highest_step\n",
    "        nodes.set_array(node_color_values)\n",
    "        nodes.set_alpha(1.0)\n",
    "        if num < len(path) - 1:\n",
    "            next_node = path[num + 1]\n",
    "            edge = (current_node, next_node) if (current_node, next_node) in edge_list else (next_node, current_node)\n",
    "            if edge in edge_list:\n",
    "                edge_index = edge_list.index(edge)\n",
    "                edge_colors[edge_index] = color_map(visited.get(current_node, 0) / highest_step)\n",
    "                edges.set_edgecolor(edge_colors)\n",
    "        current_bin_id = visited.get(current_node, 0)\n",
    "        current_text.set_text(f'Time Course (s): {current_bin_id * 0.09287981859410431:.2f}')\n",
    "\n",
    "        return nodes, edges, current_text\n",
    "\n",
    "    # Color bar setup\n",
    "    sm = plt.cm.ScalarMappable(cmap=color_map, norm=plt.Normalize(vmin=0, vmax=highest_step))\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(sm, ax=ax, orientation='vertical', fraction=0.02, pad=0.04)\n",
    "    cbar.set_label('Step in Random Walk')\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=highest_step, repeat=False, blit=True)\n",
    "    ani.save(os.path.join(f'{graphics_path}/maximal_entropy', 'random_walk_animation.mp4'), writer='ffmpeg', fps=fps, extra_args=['-vcodec', 'libx264', '-pix_fmt', 'yuv420p', '-crf', '18', '-preset', 'veryfast'])\n",
    "    plt.close(fig)\n",
    "\n",
    "    # Save the last frame as SVG\n",
    "    nodes.set_array(node_color_values)  # Set final colors for nodes\n",
    "    nodes.set_alpha(1.0)  # Ensure all nodes are fully opaque in the final frame\n",
    "    fig.savefig(os.path.join(f'{graphics_path}/maximal_entropy', 'final_random_walk_frame.svg'), format='svg', transparent=True, bbox_inches='tight')\n",
    "\n",
    "    return ani\n",
    "\n",
    "\n",
    "### Main sampling and plotting:\n",
    "def plot_indices(indices, total_bins, method_name, file_id_colors=None, file_ids_at_indices=None):\n",
    "    \"\"\"Plot the indices as a time series to visualize the selection sequence and color them by file_id.\"\"\"\n",
    "    print(\"Indices length:\", len(indices))\n",
    "    print(\"File IDs at Indices length:\", len(file_ids_at_indices))\n",
    "    print(\"Sample indices values:\", indices[:10])\n",
    "    print(\"Sample file IDs at indices values:\", file_ids_at_indices[:10])\n",
    "\n",
    "    # Check and handle total_bins if it's an np.array\n",
    "    if isinstance(total_bins, np.ndarray):\n",
    "        print(\"total_bins is an np.array:\", total_bins)\n",
    "        total_bins_count = len(total_bins)  # Assuming you want the count of bins if it's an array\n",
    "    else:\n",
    "        total_bins_count = total_bins\n",
    "\n",
    "    print(f'Total bins count: {total_bins_count}')\n",
    "\n",
    "    label_step = max(1, total_bins_count // 30)\n",
    "    label_size = min(10, max(5, 500 // total_bins_count))\n",
    "\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    if file_id_colors and file_ids_at_indices:\n",
    "        colors = [file_id_colors.get(file_id, 'grey') for file_id in file_ids_at_indices]\n",
    "    else:\n",
    "        colors = ['blue'] * len(indices)\n",
    "    colors = colors[:len(indices)]\n",
    "    unique_colors = set(colors)\n",
    "    color_labels = {color: file_id for file_id, color in file_id_colors.items() if color in unique_colors}\n",
    "    for color, label in color_labels.items():\n",
    "        specific_indices = [i for i, c in enumerate(colors) if c == color]\n",
    "        specific_indices = np.clip(specific_indices, 0, len(indices) - 1)\n",
    "        specific_values = [indices[i] for i in specific_indices]\n",
    "        plt.scatter(specific_indices, specific_values, color=color, label=label)\n",
    "    plt.plot(indices, 'grey', label='sampling sequence', alpha=0.4)  # Using grey to keep focus on points\n",
    "    bin_labels = [str(i) if i % label_step == 0 else '' for i in range(total_bins_count)]\n",
    "    plt.yticks(np.arange(0, total_bins_count, label_step), bin_labels[::label_step], fontsize=label_size)\n",
    "    plt.xlabel('Sample Step')\n",
    "    plt.ylabel('Bin ID')\n",
    "    plt.title(f'Bin Sampling Sequence for {method_name}')\n",
    "    plt.legend(title=\"File IDs\")\n",
    "    plt.grid(True)\n",
    "    global graphics_path\n",
    "    output_dir = f'{graphics_path}/{method_name}'\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, f'sample_plot_{method_name}.svg'), format='svg', transparent=True, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling Procedure / Database Structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eskzYELHXQtB"
   },
   "outputs": [],
   "source": [
    "def sample_data(epoch_data, file_ids, indices_color_mapping=None, cross_file_sampling=False, method='ornstein-uhlenbeck', sample_size=1, clip_bins=False, use_fallback=True, **params):\n",
    "    all_samples = {}\n",
    "    if cross_file_sampling:\n",
    "        sampled_data = {'all': {'original': {'real': {}, 'imaginary': {}},\n",
    "                                  'lossy': {'real': {}, 'imaginary': {}}}}\n",
    "        chosen_file_ids = []\n",
    "    else:\n",
    "        sampled_data = {file_id: {'original': {'real': {}, 'imaginary': {}},\n",
    "                                  'lossy': {'real': {}, 'imaginary': {}}}\n",
    "                        for file_id in file_ids}\n",
    "\n",
    "    print_initial_bin_counts(sampled_data, epoch_data, cross_file_sampling, file_ids)\n",
    "\n",
    "    all_bins = {}\n",
    "    for file_id in file_ids:\n",
    "        print(f\"Processing file_id: {file_id}\")\n",
    "        if file_id not in epoch_data:\n",
    "            raise ValueError(f\"No data found for file_id '{file_id}'.\")\n",
    "        for processing_type in ['original', 'lossy']:\n",
    "            for component_type in ['real', 'imaginary']:\n",
    "                key = (file_id, processing_type, component_type)\n",
    "                if key not in all_bins:\n",
    "                    all_bins[key] = []\n",
    "                all_bins[key] = get_sorted_bin_keys(epoch_data[file_id][processing_type][component_type])\n",
    "    # Flatten the list of lists of keys and then sort uniquely\n",
    "    flat_list_of_keys = [bin_key for sublist in all_bins.values() for bin_key in sublist]\n",
    "    unique_bins_list = get_sorted_bin_keys({key: None for key in set(flat_list_of_keys)})\n",
    "\n",
    "    print(f\"Unique bins list: {unique_bins_list}\")\n",
    "    num_samples = min(sample_size, len(unique_bins_list))\n",
    "    bin_min, bin_max = 0, len(unique_bins_list) - 1\n",
    "    indices, html_video = stochastic_process(method, unique_bins_list, num_samples, bin_min, bin_max, **params)\n",
    "    if clip_bins:\n",
    "        selected_bins = wrap_indices(indices, unique_bins_list)\n",
    "    else:\n",
    "        selected_bins = [unique_bins_list[i] for i in indices if 0 <= i < len(unique_bins_list)]\n",
    "    print(f\"Selected bins: {selected_bins}\")\n",
    "    file_ids_at_indices = []\n",
    "    if cross_file_sampling:\n",
    "        bin_to_file = copy_selected_bins_cross_file(sampled_data, all_bins, epoch_data, selected_bins)\n",
    "        file_ids_at_indices = [bin_to_file.get(bin_key, 'Unknown') for bin_key in selected_bins]\n",
    "    else:\n",
    "        for file_id in file_ids:\n",
    "            for processing_type in ['original', 'lossy']:\n",
    "                for component_type in ['real', 'imaginary']:\n",
    "                    target = sampled_data[file_id][processing_type][component_type]\n",
    "                    source = epoch_data[file_id][processing_type][component_type]\n",
    "                    copy_selected_bins(target, [source], selected_bins, use_fallback)\n",
    "    sampleset_timeseries = plot_indices(indices, len(indices), method, indices_color_mapping, file_ids_at_indices)\n",
    "    return sampled_data, sampleset_timeseries, file_ids_at_indices if cross_file_sampling else []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fpLWQB2xYNvr"
   },
   "outputs": [],
   "source": [
    "# strict typing\n",
    "def copy_selected_bins_cross_file(\n",
    "    target: Dict[str, Any],\n",
    "    all_bins: Dict[Tuple[str, str, str], List[str]],\n",
    "    epoch_data: Dict[str, Dict[str, Dict[str, Dict[str, Any]]]],\n",
    "    selected_bins: List[str]\n",
    ") -> Dict[str, str]:\n",
    "    \"\"\"Populate the target dictionary with data associated with each selected bin, with type checks and diagnostics.\"\"\"\n",
    "    bin_to_file = {}\n",
    "    for bin_key in selected_bins:\n",
    "        available_files = [file_id for (file_id, p_type, c_type), bins in all_bins.items() if bin_key in bins]\n",
    "        if available_files:\n",
    "            chosen_file_id = random.choice(available_files)\n",
    "            bin_to_file[bin_key] = chosen_file_id\n",
    "            for processing_type in ['original', 'lossy']:\n",
    "                for component_type in ['real', 'imaginary']:\n",
    "                    source = epoch_data[chosen_file_id][processing_type][component_type]\n",
    "                    if bin_key in source:\n",
    "                        if 'all' not in target:\n",
    "                            target['all'] = {}\n",
    "                        if processing_type not in target['all']:\n",
    "                            target['all'][processing_type] = {}\n",
    "                        if component_type not in target['all'][processing_type]:\n",
    "                            target['all'][processing_type][component_type] = []\n",
    "                        elif isinstance(target['all'][processing_type][component_type], dict):\n",
    "                            target['all'][processing_type][component_type] = []  # Resetting it to a list if it's incorrectly a dict\n",
    "                        target['all'][processing_type][component_type].append({\n",
    "                            'bin_key': bin_key,\n",
    "                            'data': source[bin_key]\n",
    "                        })\n",
    "        else:\n",
    "            print(f\"No available files for bin {bin_key}\")\n",
    "\n",
    "    return bin_to_file\n",
    "\n",
    "def dump_lists_to_directories(lists_dict):\n",
    "    base_path = \"/content/Model/graphics\"\n",
    "    dir_map = {\n",
    "        \"_me\": \"maximal_entropy\",\n",
    "        \"_rossler\": \"rossler\",\n",
    "        \"_ou\": \"ornstein-uhlenbeck\",\n",
    "        \"_srs\": \"simple_random_shuffle\"\n",
    "    }\n",
    "\n",
    "    for list_name, list_obj in lists_dict.items():\n",
    "        pattern = None\n",
    "        optional_number = None\n",
    "\n",
    "        for key in dir_map.keys():\n",
    "            if list_name.endswith(key):\n",
    "                pattern = key\n",
    "                break\n",
    "\n",
    "        if pattern is None:\n",
    "            print(f\"No valid pattern found in list name: {list_name}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            optional_number = int(''.join(filter(str.isdigit, list_name.split(pattern)[-1])))\n",
    "        except ValueError:\n",
    "            optional_number = None\n",
    "\n",
    "        if optional_number is not None:\n",
    "            target_dir = os.path.join(\"/content/Model\", f\"graphics_sample{optional_number}\", dir_map[pattern])\n",
    "        else:\n",
    "            target_dir = os.path.join(base_path, dir_map[pattern])\n",
    "\n",
    "        os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "        file_path = os.path.join(target_dir, f\"{list_name}_order_of_bins.json\")\n",
    "        with open(file_path, 'w') as f:\n",
    "            json.dump(list_obj, f)\n",
    "\n",
    "        print(f\"List '{list_name}' dumped to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cXatRRQ966p"
   },
   "outputs": [],
   "source": [
    "def save_dict_as_tar_gz(dictionary, filename):\n",
    "    pickle_filename = 'dictionary.pkl'\n",
    "    with open(pickle_filename, 'wb') as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "    gzip_filename = f'{pickle_filename}.gz'\n",
    "    with open(pickle_filename, 'rb') as f_in:\n",
    "        with gzip.open(gzip_filename, 'wb') as f_out:\n",
    "            f_out.writelines(f_in)\n",
    "    tar_gz_filename = f'{filename}.tar.gz'\n",
    "    with tarfile.open(tar_gz_filename, 'w:gz') as tar:\n",
    "        tar.add(gzip_filename, arcname=os.path.basename(gzip_filename))\n",
    "    os.remove(pickle_filename)\n",
    "    os.remove(gzip_filename)\n",
    "\n",
    "    print(f'Dictionary saved and compressed as {tar_gz_filename}')\n",
    "\n",
    "def load_dict_from_tar_gz(filename):\n",
    "    with tarfile.open(filename, 'r:gz') as tar:\n",
    "        tar.extractall()\n",
    "    gzip_filename = 'dictionary.pkl.gz'\n",
    "    with gzip.open(gzip_filename, 'rb') as f_in:\n",
    "        with open('dictionary.pkl', 'wb') as f_out:\n",
    "            f_out.writelines(f_in)\n",
    "    with open('dictionary.pkl', 'rb') as f:\n",
    "        dictionary = pickle.load(f)\n",
    "    os.remove('dictionary.pkl')\n",
    "    os.remove(gzip_filename)\n",
    "    print(f'Dictionary loaded from {filename}')\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mEuqYrp8F8b2"
   },
   "outputs": [],
   "source": [
    "def generate_model_path(base_path, epoch, val_loss, stochastic_process_name):\n",
    "    formatted_val_loss = f\"{val_loss:.4f}\"\n",
    "    return f\"{base_path}_{stochastic_process_name}_epoch_{epoch}_val_loss_{formatted_val_loss}.h5\"\n",
    "\n",
    "def save_model_and_config(model, filepath):\n",
    "    ensure_directory_exists(filepath)\n",
    "    model.save(filepath, save_format='h5')\n",
    "    model_json = model.to_json()\n",
    "    json_path = f\"{filepath}_config.json\"\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    print(f\"Model and configuration saved to {filepath} and {json_path}\")\n",
    "\n",
    "def extract_data(sample):\n",
    "    return sample['data']\n",
    "\n",
    "def prepare_data(real_samples, imag_samples):\n",
    "    real = np.vstack([extract_data(r) for r in real_samples])\n",
    "    imag = np.vstack([extract_data(i) for i in imag_samples])\n",
    "    real = real.reshape(-1, 100, 1)\n",
    "    imag = imag.reshape(-1, 100, 1)\n",
    "    combined = np.concatenate([real, imag], axis=-1)  # Now shape is (-1, 100, 2)\n",
    "    return combined\n",
    "\n",
    "def prepare_segmented_data(data, samples_per_segment):\n",
    "    num_samples = data.shape[0]\n",
    "    num_segments = num_samples // samples_per_segment\n",
    "    if num_samples % samples_per_segment != 0:\n",
    "        raise ValueError(\"The total number of samples is not a multiple of samples per segment.\")\n",
    "    segmented_data = data[:num_segments * samples_per_segment].reshape(-1, samples_per_segment, 100, 2)\n",
    "    return segmented_data\n",
    "\n",
    "def prepare_tensorflow_dataset(prepped_data, batch_size):\n",
    "    dataset_shape = prepped_data.shape\n",
    "    flattened_data = prepped_data.reshape(-1, dataset_shape[2], dataset_shape[3])  # Reshape to (-1, 100, 2)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((flattened_data, flattened_data))\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Terms / Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYWxQeaDvJoY"
   },
   "outputs": [],
   "source": [
    "tfd = tfp.distributions\n",
    "tfb = tfp.bijectors\n",
    "\n",
    "# Clear previous session\n",
    "K.clear_session()\n",
    "\n",
    "# Manage GPU memory growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Define the Sampling layer\n",
    "class Sampling(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        mean, logvar = inputs\n",
    "        epsilon = tf.keras.backend.random_normal(shape=tf.shape(mean))\n",
    "        return mean + tf.exp(0.5 * logvar) * epsilon\n",
    "\n",
    "# Define the Encoder\n",
    "def create_encoder(input_shape, latent_dim):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    x = layers.Flatten()(inputs)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    z_mean = layers.Dense(latent_dim)(x)\n",
    "    z_logvar = layers.Dense(latent_dim)(x)\n",
    "    z = Sampling()([z_mean, z_logvar])\n",
    "    encoder = Model(inputs, [z_mean, z_logvar, z], name='encoder')\n",
    "    return encoder\n",
    "\n",
    "# Define the Decoder\n",
    "def create_decoder(output_shape, latent_dim):\n",
    "    latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
    "    x = layers.Dense(64, activation='relu')(latent_inputs)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dense(tf.reduce_prod(output_shape), activation='sigmoid')(x)\n",
    "    outputs = layers.Reshape(output_shape)(x)\n",
    "    decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "    return decoder\n",
    "\n",
    "# Define the IAF Bijector Layer\n",
    "class IAFBijectorLayer(layers.Layer):\n",
    "    def __init__(self, latent_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.tfd.TransformedDistribution(\n",
    "    distribution=tfd.Sample(\n",
    "        tfd.Normal(loc=0., scale=1.), sample_shape=[dims]),\n",
    "    bijector=tfb.Invert(tfb.MaskedAutoregressiveFlow(\n",
    "        shift_and_log_scale_fn=tfb.AutoregressiveNetwork(\n",
    "            params=2, hidden_units=[512, 512]))))\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.iaf.forward(inputs)\n",
    "\n",
    "# Define the VAE\n",
    "def create_vae(input_shape, latent_dim):\n",
    "    encoder = create_encoder(input_shape, latent_dim)\n",
    "    decoder = create_decoder(input_shape, latent_dim)\n",
    "\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "    z_mean, z_logvar, z = encoder(inputs)\n",
    "\n",
    "    z_transformed = IAFBijectorLayer(latent_dim)(z)\n",
    "\n",
    "    outputs = decoder(z_transformed)\n",
    "\n",
    "    vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "    kl_loss = -0.5 * tf.reduce_mean(\n",
    "        1 + z_logvar - tf.square(z_mean) - tf.exp(z_logvar)\n",
    "    )\n",
    "    vae.add_loss(kl_loss)\n",
    "\n",
    "    vae.compile(optimizer=tf.keras.optimizers.Adam(), loss='mse')\n",
    "\n",
    "    return vae, encoder\n",
    "\n",
    "# Define the LatentSpaceHeatmapCallback\n",
    "class LatentSpaceHeatmapCallback(Callback):\n",
    "    def __init__(self, encoder, save_dir=\"heatmaps\"):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.plot_weights(epoch)\n",
    "\n",
    "    def plot_weights(self, epoch):\n",
    "        for layer in self.encoder.layers:\n",
    "            if isinstance(layer, layers.Dense):\n",
    "                weights, biases = layer.get_weights()\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.heatmap(weights, annot=False, cmap='viridis')\n",
    "                plt.title(f'Weights of layer {layer.name} at epoch {epoch + 1}')\n",
    "                plt.xlabel('Output Units')\n",
    "                plt.ylabel('Input Units')\n",
    "                plt.savefig(os.path.join(self.save_dir, f'epoch_{epoch + 1}_{layer.name}.png'))\n",
    "                plt.close()\n",
    "\n",
    "# Define the SaveModelAfterNBatches callback\n",
    "class SaveModelAfterNBatches(Callback):\n",
    "    def __init__(self, save_interval, save_path):\n",
    "        super().__init__()\n",
    "        self.save_interval = save_interval\n",
    "        self.save_path = save_path\n",
    "        self.batch_count = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "        if self.batch_count % self.save_interval == 0:\n",
    "            model_save_path = f\"{self.save_path}_batch_{self.batch_count}.h5\"\n",
    "            self.model.save(model_save_path)\n",
    "            print(f\"Model saved after {self.batch_count} batches at {model_save_path}\")\n",
    "            \n",
    "class LatentSpaceHeatmapCallback(Callback):\n",
    "    def __init__(self, vae, save_dir=\"heatmaps\"):\n",
    "        super().__init__()\n",
    "        self.encoder = vae.get_layer('encoder')\n",
    "        self.save_dir = save_dir\n",
    "        os.makedirs(self.save_dir, exist_ok=True)\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.plot_weights(batch)\n",
    "\n",
    "    def plot_weights(self, batch):\n",
    "        for layer in self.encoder.layers:\n",
    "            if isinstance(layer, layers.Dense):\n",
    "                weights, biases = layer.get_weights()\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                sns.heatmap(weights, annot=False, cmap='viridis')\n",
    "                plt.title(f'Weights of layer {layer.name} at batch {batch + 1}')\n",
    "                plt.xlabel('Output Units')\n",
    "                plt.ylabel('Input Units')\n",
    "                plt.savefig(os.path.join(self.save_dir, f'batch_{batch + 1}_{layer.name}.png'))\n",
    "                plt.close()\n",
    "\n",
    "class SaveModelAfterNBatches(Callback):\n",
    "    def __init__(self, save_interval, save_path):\n",
    "        super().__init__()\n",
    "        self.save_interval = save_interval\n",
    "        self.save_path = save_path\n",
    "        self.batch_count = 0\n",
    "\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        self.batch_count += 1\n",
    "        if self.batch_count % self.save_interval == 0:\n",
    "            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "            model_save_path = f\"{self.save_path}_batch_{self.batch_count}_{timestamp}.h5\"\n",
    "            self.model.save(model_save_path)\n",
    "            print(f\"Model saved after {self.batch_count} batches at {model_save_path}\")\n",
    "\n",
    "\n",
    "# Define the data preparation functions\n",
    "def generate_model_path(base_path, epoch, val_loss, stochastic_process_name):\n",
    "    formatted_val_loss = f\"{val_loss:.4f}\"\n",
    "    return f\"{base_path}_{stochastic_process_name}_epoch_{epoch}_val_loss_{formatted_val_loss}.h5\"\n",
    "\n",
    "def save_model_and_config(model, filepath):\n",
    "    ensure_directory_exists(filepath)\n",
    "    model.save(filepath, save_format='h5')\n",
    "    model_json = model.to_json()\n",
    "    json_path = f\"{filepath}_config.json\"\n",
    "    with open(json_path, 'w') as json_file:\n",
    "        json_file.write(model_json)\n",
    "    print(f\"Model and configuration saved to {filepath} and {json_path}\")\n",
    "\n",
    "def extract_data(sample):\n",
    "    return sample['data']\n",
    "\n",
    "def prepare_data(real_samples, imag_samples):\n",
    "    real = np.vstack([extract_data(r) for r in real_samples])\n",
    "    imag = np.vstack([extract_data(i) for i in imag_samples])\n",
    "    real = real.reshape(-1, 100, 1)\n",
    "    imag = imag.reshape(-1, 100, 1)\n",
    "    combined = np.concatenate([real, imag], axis=-1)  # Now shape is (-1, 100, 2)\n",
    "    return combined\n",
    "\n",
    "def prepare_tensorflow_dataset(prepped_data, batch_size):\n",
    "    dataset_shape = prepped_data.shape\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((prepped_data, prepped_data))\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remux + IFFT Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not yet implemented - just requires me to set aside time to reverse process of tensor stacking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pre-Processing\n",
    "\n",
    "# Randomly sample the Kevin Macleod catalog from online, and download the 10 songs chosen in an organized fashion\n",
    "pathinit = append_base_path(workingdirectory, urlstxtdir)[0] + '/urls.txt'\n",
    "macleodsample = macleodchance(pathinit, 10)\n",
    "audiopaths = append_base_path(workingdirectory, audiosampledir)[0]\n",
    "macleodownthemall = macleodownload(macleonline, macleodsample, audiopaths)\n",
    "audiorandomsample = append_dataset(audiopaths)\n",
    "\n",
    "# Do the pre-processing (cochlear filtration, lossy and lossless coding, DFT, and dictionary structuring)\n",
    "experimental_dataset, outputs = configure_epochs(audiorandomsample, duration=10, fft_size=4096, downloadfile=False, rectify=False, min_frequency=20, max_frequency=20000, num_frequency_bins=400, bw=None, with_lossy_backprop=True, UseDualMono=False, backend='pytorch', use_gpu=True)\n",
    "\n",
    "# Auto backup the processed sets of arrays for each file \n",
    "save_path = append_base_path(workingdirectory, arraydir)\n",
    "exarrays, extract_timestamp = extract_and_save_data_arrays_with_timestamp(experimental_dataset)\n",
    "with open(f'{save_path[0]}/sampledfrommacleod_{extract_timestamp}.json', 'w') as file:\n",
    "    json.dump(macleodsample, file)\n",
    "    \n",
    "# reload the entirety of the dataset and unpack into the correct structure in memory if necessary by uncommenting ->\n",
    "# test = load_and_rebuild_structure('/content/Model/Preprocessed_Arrays/metadata_1715470570.json',\n",
    "#                                         '/content/Model/Preprocessed_Arrays/saved_arrays_1715470570.npz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run stochastic methods + generate visualizations of each window over time - across an audio file or within audio files.\n",
    "# Five runs of each stochastic process, using the sample_data function, returning three objects each.\n",
    "\n",
    "all_files = nab_fileids(experimental_dataset)\n",
    "cmap = create_color_mapping(all_files, 'Dark2')\n",
    "graphics_path = '/content/Model/graphics_sample'\n",
    "\n",
    "## one day this will be a loop for i > 5... for now just run the same code snips five times with different namings\n",
    "\n",
    "### 1/5 runs of stoch methods\n",
    "# Maximal Entropy Random Walk: \n",
    "all_samples_me, timeseries_me, checkcrossfiles_me = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"maximal_entropy\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "\n",
    "# ^ In sample_data, object one is the set of stacked / stochastically shuffled tensor bins, object two is the matplotlib plot,\n",
    "# ^ And object three is a list of the audio tracks corresponding to each bin if cross_file_sampling is true.\n",
    "\n",
    "# Rössler Attractor:\n",
    "all_samples_rossler, timeseries_rossler, checkcrossfiles_rossler = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"rossler\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "# Ohnstein-Uhlenbeck:\n",
    "all_samples_ou, timeseries_ou, checkcrossfiles_ou = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"ornstein-uhlenbeck\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "# Simple Random Sample:\n",
    "all_samples_srs, timeseries_srs, checkcrossfiles_srs = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"simple_random_shuffle\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "set1 = {\"checkcrossfiles_me\": checkcrossfiles_me, \"checkcrossfiles_rossler\": checkcrossfiles_rossler, \"checkcrossfiles_ou\": checkcrossfiles_ou, \"checkcrossfiles_srs\": checkcrossfiles_srs}\n",
    "# Dump the dictionary of named lists to the filesystem, alongside the generated visualizations.\n",
    "dump_lists_to_directories(set1)\n",
    "\n",
    "#### 2/5 runs\n",
    "graphics_path = '/content/Model/graphics_sample2'\n",
    "cmap = create_color_mapping(all_files, 'tab20')\n",
    "all_samples_me2, timeseries_me2, checkcrossfiles_me2 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"maximal_entropy\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "all_samples_rossler2, timeseries_rossler2, checkcrossfiles_rossler2 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"rossler\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108, randomize=True)\n",
    "all_samples_ou2, timeseries_ou2, checkcrossfiles_ou2 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"ornstein-uhlenbeck\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108, randomize=True)\n",
    "all_samples_srs2, timeseries_srs2, checkcrossfiles_srs2 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"simple_random_shuffle\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "set2 = {\"checkcrossfiles_me2\": checkcrossfiles_me, \"checkcrossfiles_rossler2\": checkcrossfiles_rossler, \"checkcrossfiles_ou2\": checkcrossfiles_ou, \"checkcrossfiles_srs2\": checkcrossfiles_srs}\n",
    "dump_lists_to_directories(set2)\n",
    "\n",
    "#### 3/5 runs\n",
    "graphics_path = '/content/Model/graphics_sample3'\n",
    "cmap = create_color_mapping(all_files, 'tab20b')\n",
    "all_samples_me3, timeseries_me3, checkcrossfiles_me3 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"maximal_entropy\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "all_samples_rossler3, timeseries_rossler3, checkcrossfiles_rossler3 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"rossler\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108, randomize=True)\n",
    "all_samples_ou3, timeseries_ou3, checkcrossfiles_ou3 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"ornstein-uhlenbeck\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108, randomize=True)\n",
    "all_samples_srs3, timeseries_srs3, checkcrossfiles_srs3 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"simple_random_shuffle\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "set3 = {\"checkcrossfiles_me3\": checkcrossfiles_me, \"checkcrossfiles_rossler3\": checkcrossfiles_rossler, \"checkcrossfiles_ou3\": checkcrossfiles_ou, \"checkcrossfiles_srs3\": checkcrossfiles_srs}\n",
    "dump_lists_to_directories(set3)\n",
    "\n",
    "#### 4/5 runs\n",
    "graphics_path = '/content/Model/graphics_sample4'\n",
    "cmap = create_color_mapping(all_files, 'tab20c')\n",
    "all_samples_me4, timeseries_me4, checkcrossfiles_me4 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"maximal_entropy\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "all_samples_rossler4, timeseries_rossler4, checkcrossfiles_rossler4 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"rossler\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108, randomize=True)\n",
    "all_samples_ou4, timeseries_ou4, checkcrossfiles_ou4 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"ornstein-uhlenbeck\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108, randomize=True)\n",
    "all_samples_srs4, timeseries_srs4, checkcrossfiles_srs4 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"simple_random_shuffle\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "set4 = {\"checkcrossfiles_me4\": checkcrossfiles_me, \"checkcrossfiles_rossler4\": checkcrossfiles_rossler, \"checkcrossfiles_ou4\": checkcrossfiles_ou, \"checkcrossfiles_srs4\": checkcrossfiles_srs}\n",
    "dump_lists_to_directories(set4)\n",
    "\n",
    "#### 5/5 runs\n",
    "graphics_path = '/content/Model/graphics_sample5'\n",
    "cmap = create_color_mapping(all_files, 'Set3')\n",
    "all_samples_me5, timeseries_me5, checkcrossfiles_me5 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"maximal_entropy\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "all_samples_rossler5, timeseries_rossler5, checkcrossfiles_rossler5 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"rossler\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108, randomize=True)\n",
    "all_samples_ou5, timeseries_ou5, checkcrossfiles_ou5 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"ornstein-uhlenbeck\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108, randomize=True)\n",
    "all_samples_srs5, timeseries_srs5, checkcrossfiles_srs5 = sample_data(experimental_dataset, all_files, indices_color_mapping=cmap, cross_file_sampling=True, method=\"simple_random_shuffle\", clip_bins=False, use_fallback=False, visualize=True, sample_size=108)\n",
    "set5 = {\"checkcrossfiles_me5\": checkcrossfiles_me, \"checkcrossfiles_rossler5\": checkcrossfiles_rossler, \"checkcrossfiles_ou5\": checkcrossfiles_ou, \"checkcrossfiles_srs5\": checkcrossfiles_srs}\n",
    "dump_lists_to_directories(set5)\n",
    "\n",
    "# You can save and load the actual content of each sampled set of audio arrays as a .pkl if need be with a call like so -->\n",
    "# save_dict_as_tar_gz(all_samples_me, 'merw_save')\n",
    "\n",
    "# and reload if need be, like so -->\n",
    "# all_samples_me = load_dict_from_tar_gz('drive/MyDrive/merw_save.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example separating the arrays for each all_samples_me - uncomment this when doing your own\n",
    "real_data_error = np.array(extract_data_arrays(all_samples_me, processing_type='original', component_type='real'))\n",
    "imaginary_data_error = np.array(extract_data_arrays(all_samples_me, processing_type='original', component_type='imaginary'))\n",
    "real_data_train = np.array(extract_data_arrays(all_samples_me, processing_type='lossy', component_type='real'))\n",
    "imaginary_data_train = np.array(extract_data_arrays(all_samples_me, processing_type='lossy', component_type='imaginary'))\n",
    "\n",
    "train_prep = prepare_data(real_data_train, imaginary_data_train)  # Prepares training data\n",
    "train_dataset = prepare_tensorflow_dataset(train_prep, 128)       # Prepare TensorFlow dataset for training with batch size 128\n",
    "\n",
    "val_prep = prepare_data(real_data_error, imaginary_data_error)    # Prepares validation data\n",
    "val_dataset = prepare_tensorflow_dataset(val_prep, 128)           # Prepare TensorFlow dataset for validation with batch size 128\n",
    "\n",
    "# Declare and Compile Model\n",
    "input_shape = (100, 2)\n",
    "latent_dim = 16\n",
    "\n",
    "vae, encoder = create_vae(input_shape, latent_dim)\n",
    "vae.summary()\n",
    "\n",
    "# Now, add callbacks to the compiled model\n",
    "heatmap_callback = LatentSpaceHeatmapCallback(vae)\n",
    "save_model_callback = SaveModelAfterNBatches(save_interval=100, save_path='vae_model')\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the VAE model with the custom callbacks\n",
    "history = vae.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=50,\n",
    "    callbacks=[heatmap_callback, save_model_callback, early_stopping_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N7qPmoipRtbq"
   },
   "outputs": [],
   "source": [
    "\n",
    "plot_model(\n",
    "    vae,\n",
    "    to_file='minimal_model_plot_model.png',\n",
    "    show_shapes=True,\n",
    "    show_layer_names=True,\n",
    "    rankdir='TB'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dfaygpm9LKYv"
   },
   "outputs": [],
   "source": [
    "# iPython tar for Colab\n",
    "# !tar -czvf heatmapz.tar.gz /content/heatmaps"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOccDGqmVlKKpDsG2Dqo6MW",
   "gpuType": "L4",
   "machine_shape": "hm",
   "mount_file_id": "1vPiDRGeGvpR-uRBeEPuOEXrW8LECsq_f",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
